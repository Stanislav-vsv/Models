
# coding: utf-8

# In[1]:


get_ipython().run_cell_magic('time', '', '\n# coding: utf-8\nimport argparse\nfrom time import gmtime, strftime\nparser = argparse.ArgumentParser(description=\'MLM Environment Variables\')\nparser.add_argument(\'--login\', default=\'VKOKHTEV\')\nparser.add_argument(\'--password\', default=\'VKOKHTEV$\')\nparser.add_argument(\'--tns\', default="""(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=dsacrmap)(PORT=1521)))(CONNECT_DATA=(SID=DMMLMPLT)(SERVER=DEDICATED)))""")\nparser.add_argument(\'--job\', default=strftime("%y%m%d%H%M%S9900002", gmtime()))\nargs = vars(parser.parse_known_args()[0])\nprint("JOB:"+args["job"]+" Login:"+args["login"]+" Pwd:"+args["password"]+" TNS:"+args["tns"])\n\nimport pandas as pd\nimport numpy as np\npd.set_option("display.max_columns",40)\nimport warnings\nfrom gensim.models.word2vec import LineSentence\nfrom gensim.models.fasttext import FastText\nfrom sklearn import preprocessing\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import ParameterGrid\nimport time\nfrom sklearn.metrics import average_precision_score\nimport cx_Oracle\nimport datetime\n\npd.set_option("display.max_columns",40)\nwarnings.filterwarnings(\'ignore\')\nnp.random.seed(0)\n\n###### Get connection\nconn_bi = cx_Oracle.connect(args["login"],args["password"], args["tns"])\ncursor_bi = conn_bi.cursor()\n\n################### НЕФТЬ ###################\noil_str = "select * from MACRODATA.BRENT"\noil = pd.read_sql(oil_str, conn_bi)\n#++++++++++++++++++++++++++++\n# oil = pd.read_csv(\'Brent.csv\',sep=\';\')\n# oil.columns = [\'VALUE_DAY\',\'TRADE_OPEN\']\n# oil[\'TRADE_OPEN\'] = oil[\'TRADE_OPEN\'].apply(lambda x: x.replace(\',\',\'.\')).astype(float)\n# oil[\'VALUE_DAY\'] = pd.to_datetime(oil[\'VALUE_DAY\'],format=\'%d.%m.%Y\')\n#++++++++++++++++++++++++++++\noil.sort_values(by=[\'VALUE_DAY\'],inplace=True)\noil.index = oil[\'VALUE_DAY\']\noil = oil.resample("1d").interpolate("time")[[\'TRADE_OPEN\']]\noil.columns=[\'value\']\noil[\'DATE\'] = oil.index\noil.name = \'oil\'\n\n################### ПРОЦЕНТНАЯ СТАВКА ###################\nmiacr_str = "select * from MACRODATA.MIACR"\nmiacr = pd.read_sql(miacr_str, conn_bi)\n#++++++++++++++++++++++++++++\n# miacr = pd.read_csv(\'MIACR.csv\',sep=\';\')\n# miacr.columns = [\'VALUE_DAY\',\'LAST_QUOTE_CLOSE\']\n# miacr[\'LAST_QUOTE_CLOSE\'] = miacr[\'LAST_QUOTE_CLOSE\'].apply(lambda x: x.replace(\',\',\'.\'))\n# miacr[\'VALUE_DAY\'] = pd.to_datetime(miacr[\'VALUE_DAY\'],format=\'%d.%m.%Y\')\n#++++++++++++++++++++++++++++\nmiacr.sort_values(by=[\'VALUE_DAY\'],inplace=True)\nlower_miacr = pd.DataFrame(miacr.iloc[-1,:].copy()).T\nlower_miacr[\'VALUE_DAY\'] += pd.Timedelta(30,unit=\'d\')\nupper_miacr = pd.DataFrame(miacr.iloc[0,:].copy()).T\nupper_miacr[\'VALUE_DAY\'] -= pd.Timedelta(30,unit=\'d\')\nmiacr = pd.concat([upper_miacr,miacr,lower_miacr],axis=0)\nmiacr[\'LAST_QUOTE_CLOSE\'] = miacr[\'LAST_QUOTE_CLOSE\'].astype(float)\nmiacr.index = pd.to_datetime(miacr[\'VALUE_DAY\'])\nmiacr = miacr.resample("1d").interpolate("time")[[\'LAST_QUOTE_CLOSE\']]\nmiacr.columns=[\'value\']\nmiacr[\'DATE\'] = miacr.index\nmiacr.name = \'miacr\'\n\n################### ВВП ###################\ngdp_str = "select * from MACRODATA.GDP"\ngdp = pd.read_sql(gdp_str, conn_bi)\n\nlower_gdp = pd.DataFrame(gdp.iloc[-1,:].copy()).T\nlower_gdp[\'VALUE_DAY\'] -= pd.Timedelta(95,unit=\'d\')\nupper_gdp = pd.DataFrame(gdp.iloc[0,:].copy()).T\nupper_gdp[\'VALUE_DAY\'] += pd.Timedelta(365,unit=\'d\')\n\ngdp = pd.concat([upper_gdp,gdp,low_gdp],axis=0)\ngdp.index = pd.to_datetime(gdp[\'VALUE_DAY\'])\ngdp[\'value\'] = gdp[\'GDP_USD_BN_2011\'].astype(int)\ngdp.drop([\'VALUE_DAY\',\'GDP_USD_BN_2011\',\'GDP_USD_BN_2016\'],axis=1,inplace=True)\ngdp = gdp.resample("1d").interpolate("time")\n\ngdp[\'DATE\'] = gdp.index\ngdp.name = \'gdp\'\n\n\n################### ИНФЛЯЦИЯ, БЕЗРАБОТИЦА ###################\ninf_unemp_str = "select * from MACRODATA.INFLAT_UNEMPLOY"\ninf_unemp = pd.read_sql(inf_unemp_str, conn_bi)\n\nlower_inf_unemp = pd.DataFrame(inf_unemp.iloc[-1,:].copy()).T\nlower_inf_unemp[\'VALUE_DAY\'] -= pd.Timedelta(60,unit=\'d\')\nupper_inf_unemp = pd.DataFrame(inf_unemp.iloc[0,:].copy()).T\nupper_inf_unemp[\'VALUE_DAY\'] += pd.Timedelta(180,unit=\'d\')\n\ninf_unemp = pd.concat([upper_inf_unemp,inf_unemp,lower_inf_unemp],axis=0)\ninf_unemp[[\'INFLAT\',\'UNEMPLOY\']] = inf_unemp[[\'INFLAT\',\'UNEMPLOY\']].astype(float)\ninf_unemp.index = pd.to_datetime(inf_unemp[\'VALUE_DAY\'])\ndel inf_unemp[\'VALUE_DAY\']\ninf_unemp = inf_unemp.resample("1d").interpolate("time")\ninf_unemp[\'DATE\'] = inf_unemp.index\n\n################### ИНФЛЯЦИЯ ###################\ninflation = inf_unemp[[\'DATE\',\'INFLAT\']].copy()\ninflation.columns = [\'DATE\',\'value\']\ninflation.name = \'inflation\'\n\n################### БЕЗРАБОТИЦА ###################\nunemp = inf_unemp[[\'DATE\',\'INFLAT\']].copy()\nunemp.columns = [\'DATE\',\'value\']\nunemp.name = \'unemp\'\n\n\n################### КУРСЫ ВАЛЮТ ###################\nexch_str = "select * from GUARANT.EXCHANGERATE_STAT"\nexch = pd.read_sql(exch_str, conn_bi)\nexch.drop([\'XK\',\'XRATETYPE_UK\',\'CURRENCY_FROM_UK\',\'CURRENCY_TO_UK\',\\\n          \'DWSCMIX\',\'JOB_INSERT\',\'AS_OF_DAY\',\'DQ_MISTAKECOST_UK\',\\\n          \'DQ_CONTROL_UK_LIST\',\'JOB_UPDATE\',\'DELETED_FLAG\',\'CURRENCY_FROM_CCODE\'],axis=1,inplace=True)\nexch.sort_values(by=[\'VALUE_DAY\'],inplace=True)\nexch.index = exch[\'VALUE_DAY\']\nexch.columns = [\'DATE\',\'value\',\'code\']\n\neuro, dollar = exch[exch[\'code\'] == \'EUR\'], exch[exch[\'code\'] == \'USD\']\neuro.name, dollar.name = \'euro\', \'dollar\'\ndel euro[\'code\'], dollar[\'code\'], exch\n\n\n# gdp = pd.read_csv(\'gdp1.csv\',encoding=\'utf-8\',sep=\';\',index_col=0)\n# inflation = pd.read_csv(\'inflation.csv\',encoding=\'utf-8\',sep=\';\',index_col=0)\n# unemp = pd.read_csv(\'unemp.csv\',encoding=\'utf-8\',sep=\';\',index_col=0)\n# euro = pd.read_csv(\'euro.csv\',encoding=\'utf-8\',sep=\';\',index_col=0)\n# dollar = pd.read_csv(\'dollar.csv\',encoding=\'utf-8\',sep=\';\',index_col=0)\n\nfor df in [oil, miacr, gdp, inflation, unemp, euro, dollar]:\n    df[\'DATE\'] = pd.to_datetime(df[\'DATE\'])\n    df.index = pd.to_datetime(df.index)\n    df[\'num\'] = np.arange(df.shape[0])\n\ndata = pd.read_sql("select * from GUARANT.DEALGUARANTEE", conn_bi)\n# data = pd.read_csv(\'data.csv\',sep=\';\',index_col=0)\n\n\nCURRENT_DAY = pd.to_datetime(data[\'VALUE_DAY\'][0])\nfor col in [\'START_DATE\',\'END_PLAN_DATE\',\'END_FACT_DATE\']:\n    data[col] = pd.to_datetime((data[col].astype(str)).apply(lambda x: x.replace(\'5999\',\'2030\')))\n    \ndata = data[(data[\'DEAL_CURRENCY\'] == \'RUR\') | (data[\'DEAL_CURRENCY\'] == \'USD\') | (data[\'DEAL_CURRENCY\'] == \'EUR\')]\ndata.sort_values(by=[\'START_DATE\'],inplace=True)\n# Оставляем данные в заданных временных границах\ndata = data[(data[\'START_DATE\'] >= pd.to_datetime(\'01.01.2012\')) & (data[\'END_PLAN_DATE\'] < (CURRENT_DAY + pd.Timedelta(30,unit=\'D\')))] ## тут текущий день (есть в таблице) + 30 дней\n######## 2012\ndata.drop([\'VALUE_DAY\',\'DEAL_FRONT_REF\',\'MODULE_FRONT_CCODE\',\n           \'DEAL_BACK_REF\',\'MODULE_BACK_CCODE\',\n           \'DEALCLASS_CCODE\',\'DEALKIND_CCODE\',\'BENEFICIAR_PIN\',\n           \'BRANCH_EQ_CCODE\',\'PROFITCENTER_ENG_CCODE\',\n           \'LOANPURPOSE_CCODE\',\'ADVREPAYRIGHT_CCODE\',\'PRODUCT_CCODE\',\n           \'DEAL_CUR_AMT\',\'DELAY_FLAG\'],1,inplace=True)\n\ndata[\'BENEFICIAR_NAME\'].fillna(\'Не определено\',inplace=True)\ndata[[\'COMISSION_RATE\',\'USED_AMOUNT\']] = data[[\'COMISSION_RATE\',\'USED_AMOUNT\']].fillna(0)\ndata[\'USED_CURRENCY\'].fillna(\'RUR\',inplace=True)\ndata.drop_duplicates(subset=[\'DEAL_UK\'],keep=\'last\',inplace=True)\ndata[\'DURATION\'] = (data[\'END_PLAN_DATE\'] - data[\'START_DATE\']).apply(lambda x: x.days)\n\ndata.index = np.arange(data.shape[0])\n\ndef sum_to_roubles(price,curr_type,time):\n    if curr_type == \'USD\':\n        return (price * dollar[dollar[\'DATE\'] == time][\'value\']).values[0]\n    elif curr_type == \'EUR\':\n        return (price * euro[euro[\'DATE\'] == time][\'value\']).values[0]\n    else:\n        return price\n\n\n# В пустой лист запишем сумму в рублях для каждой сделки и добавим лист как признак в таблицу\nsum_arr = []\nused_arr = []\nfor i in (data.index):\n    row = data.iloc[i,:]\n    day = min(row[\'END_PLAN_DATE\']-pd.Timedelta(30,unit=\'d\'),CURRENT_DAY-pd.Timedelta(3,unit=\'d\')).replace(hour=0, minute=0, second=0)\n    sum_arr.append(sum_to_roubles(row[\'DEAL_START_AMOUNT\'],row[\'DEAL_CURRENCY\'],day))\n    used_arr.append(sum_to_roubles(row[\'USED_AMOUNT\'],row[\'USED_CURRENCY\'],day))\ndata[\'DEAL_AMOUNT_RUB\'] = sum_arr\ndata[\'USED_AMOUNT\'] = used_arr\ndata.drop([\'DEAL_START_AMOUNT\',\'USED_CURRENCY\'],axis=1,inplace=True)\ndel sum_arr\n\n# Простейшие замены с неплохим качеством\ndata[\'PRINCIPAL_NAME\'] = data[\'PRINCIPAL_NAME\'].apply(lambda x: x.lower().replace(\'федеральное государственное унитарное предприятие\',\'фгуп\').replace(\'открытое акционерное общество\',\'оао\').replace(\'публичное акционерное общество\',\'пао\').replace(\'акционерное общество\',\'ао\').replace(\'закрытое акционерное общество\',\'зао\').replace(\'общество с ограниченной ответственностью\',\'ооо\').replace(\'общество с ограниченной ответсвенностью\',\'ооо\').replace(\'закрытое ао\',\'зао\').replace(\'"\',\'\').replace(\'.\',\'\').replace(\',\',\'\'))\ndata[\'BENEFICIAR_NAME\'] = data[\'BENEFICIAR_NAME\'].apply(lambda x: x.lower().replace(\'федеральное государственное унитарное предприятие\',\'фгуп\').replace(\'открытое акционерное общество\',\'оао\').replace(\'публичное акционерное общество\',\'пао\').replace(\'акционерное общество\',\'ао\').replace(\'закрытое акционерное общество\',\'зао\').replace(\'общество с ограниченной ответственностью\',\'ооо\').replace(\'общество с ограниченной ответсвенностью\',\'ооо\').replace(\'закрытое ао\',\'зао\').replace(\'"\',\'\').replace(\'.\',\'\').replace(\',\',\'\'))\n# Если первая строка до пробела в list - возвращаем её, иначе \'неизвестно\'\ndef org_form(x):\n    if x.split(\' \')[0] in [\'фгуп\',\'оао\',\'ооо\',\'ао\',\'зао\',\'пао\']:\n        return x.split(\' \')[0]\n    else:\n        return \'неизвестно\'\ndata[\'PRINCIPAL_ORG\'] = data[\'PRINCIPAL_NAME\'].apply(org_form)\ndata[\'BENEFICIAR_ORG\'] = data[\'BENEFICIAR_NAME\'].apply(org_form)\n\ndef add_timestamps(data,N_parts):\n    result = data.copy()\n    t = pd.Series([CURRENT_DAY.replace(hour=0, minute=0, second=0)-pd.Timedelta(2,unit=\'d\')]*data.shape[0])\n    last_t = pd.DataFrame([data[\'END_PLAN_DATE\'],t]).T.min(axis=1)\n    for i in range(N_parts):\n        result[\'timestamp_\'+str(i)] = result[\'START_DATE\'].values + pd.to_timedelta((i*(last_t-result[\'START_DATE\'])/(N_parts-1)).apply(lambda x: x.days), unit=\'d\')\n    return result\n\ndef prediction(values,current_value):\n    from sklearn.linear_model import LinearRegression\n    m = LinearRegression()\n    m.fit(np.array([1,45,90]).reshape(-1, 1),np.array(values))#[20.02,17.51,15.63]\n    return np.array([m.coef_[0]*(x-1)+current_value for x in range(1,32)])\n\ndef stress_values(df, fit_values, row,is_bau=False):\n    stress_date = max(row[\'START_DATE\'],row[\'END_PLAN_DATE\'] - pd.Timedelta(30,unit=\'d\'))\n    bau_val = df.loc[:stress_date,\'value\']\n    current_value = bau_val.values[-1]\n    cols = [x for x in row.keys() if \'timestamp_\' in x]\n    if row[\'DURATION\'] < 6:\n        return len(cols)*[current_value]\n    indexes = list(df[df[\'DATE\'].isin(row[cols])][\'num\'])\n    #print(indexes)\n    if is_bau:\n        bau_val = df.loc[:,\'value\']\n        return bau_val.values[indexes]\n    else:\n        pred_stress = prediction(fit_values, current_value)\n        return np.hstack((bau_val.values,pred_stress))[indexes]\n\ndef create_overall(df,aggregate_method,N_parts):\n    add = \'_\'\n    for macro in [\'oil\',\'miacr\',\'inflation\',\'unemp\',\'gdp\',\'dollar\',\'euro\']:\n        if aggregate_method == \'mean\':\n            df[macro] = df[[macro+add+str(i) for i in range(N_parts)]].T.mean()\n        if aggregate_method == \'median\':\n            df[macro] = df[[macro+add+str(i) for i in range(N_parts)]].T.median()\n        if aggregate_method == \'max\':\n            if macro in [\'gdp\',\'miacr\',\'oil\']:\n                df[macro] = df[[macro+add+str(i) for i in range(N_parts)]].T.min()\n            else:\n                df[macro] = df[[macro+add+str(i) for i in range(N_parts)]].T.max()\n        df.drop([macro+add+str(i) for i in range(N_parts)],1,inplace=True)\n    return df\n\n\nmacro_dfs = [[oil, [20.02,17.51,15.63]],\\\n    [gdp, list(np.array([100-8.77,100-8.68,100-9.5])*150)],\\\n    [inflation, [13.22,15.56,17.68]],\\\n    [miacr, [15.96,18.12,19.69]],\\\n    [unemp, [9,10.06,11.01]],\\\n    [euro, [94.18,105.37,116.16]],\\\n    [dollar, [94.18,105.37,116.16]]]\n\nmacro = []\nmacro_stress = []   \n\nN_parts = 5\n\ndata = add_timestamps(data,N_parts)\ndata_stress = add_timestamps(data,N_parts)\n\nfor index, row in (data_stress.iterrows()):\n    vector = np.hstack([stress_values(df, fit_values, row, True) for df, fit_values in macro_dfs])\n    vector_stress = np.hstack([stress_values(df, fit_values, row, False) for df, fit_values in macro_dfs])\n    macro.append(vector)\n    macro_stress.append(vector_stress)\n    \nmacro_columns = [\'oil\',\'gdp\',\'inflation\',\'miacr\',\'unemp\',\'euro\',\'dollar\']\nmacro_cols = [x+\'_\'+str(i) for x in macro_columns for i in range(N_parts)]\nmacro_stress_df = create_overall(pd.DataFrame(macro_stress,columns=macro_cols), \'max\', N_parts)\nmacro_df = create_overall(pd.DataFrame(macro,columns=macro_cols), \'max\', N_parts)\n\ndata = pd.concat([data.loc[:,:\'BENEFICIAR_ORG\'],macro_df],axis=1)\ndata_stress = pd.concat([data_stress.loc[:,:\'BENEFICIAR_ORG\'],macro_stress_df],axis=1)\n\n\nwords = \'\\t\'.join(data[\'PRINCIPAL_NAME\'] +\' \'+ data[\'BENEFICIAR_NAME\'])\nwith open(\'text.txt\',\'w\') as f:\n    f.write(words)\nstring = LineSentence(\'text.txt\')\nfasttext = FastText(size=50,sg=0,word_ngrams=2,iter=10,min_n=2,max_n=10)\nfasttext.build_vocab(string)\nfasttext.train(string, total_examples=fasttext.corpus_count, epochs=fasttext.iter)\n\ndef to_sent_emb(string):\n    return np.sum([fasttext[x] for x in string.split(\' \') if len(x)>1],axis=0)\n\nemb_df = pd.DataFrame(np.vstack((data[\'PRINCIPAL_NAME\'] +\' \'+ data[\'BENEFICIAR_NAME\']).apply(to_sent_emb)))\nemb_df.columns = [\'emb_\'+str(w) for w in emb_df.columns]\n\ndata = pd.concat([data,emb_df],axis=1)\ndata.drop([\'PRINCIPAL_PIN\',\'PRINCIPAL_NAME\',\'BENEFICIAR_NAME\',\'USED_FLAG\',\'USED_AMOUNT\'],axis=1,inplace=True)\n\ntarget = (data_stress[\'USED_FLAG\'] == \'Y\').astype(int)\n\ndata_stress = pd.concat([data_stress, emb_df],axis=1)\ndata_stress.drop([\'PRINCIPAL_PIN\',\'PRINCIPAL_NAME\',\'BENEFICIAR_NAME\',\'USED_FLAG\'],axis=1,inplace=True)\n\ncat_columns = [\'DEAL_CURRENCY\',\'PRODUCT_NAME\',\'DEALCLASS_NAME\',\'DEALKIND_NAME\',\\\n            \'SALESPLACE_NAME\',\'PROFITCENTER_NAME\',\'LOANPURPOSE_NAME\',\'ADVREPAYRIGHT_NAME\',\\\n           \'PRINCIPAL_ORG\', \'BENEFICIAR_ORG\']\n\ndef counts(column,Y,C):\n    counts = dict()\n    global_mean = (Y == 1).sum()/Y.shape[0]\n    for elem in np.unique(column):\n        #print(elem)\n        counts[elem] = (max(0,(((column == elem) & (Y == 1)).sum())) + global_mean*C)/((column == elem).sum()+C)\n    return counts\n\ndef create_cat_features(X,Y,cat_columns,catboost=True):\n    X1 = X.copy()\n    if catboost == True:\n        for column in cat_columns:\n            le1 = preprocessing.LabelEncoder()\n            X1[column] = le1.fit_transform(X1[column])\n        \n    if catboost == False:\n        for column in cat_columns:\n            X1 = X1.replace({column:counts(X1[column],Y,0.5)})\n    return X1,Y\n\ndata_stress, target_stress = create_cat_features(data_stress, target, cat_columns, catboost=True)\ndata, target = create_cat_features(data, target, cat_columns, catboost=True)\n\ndata_train, data_test = data[data[\'END_PLAN_DATE\'] < CURRENT_DAY], data[data[\'END_PLAN_DATE\'] >= CURRENT_DAY]\ntarget_train = target.loc[data_train.index]\n\ndata_stress_train, data_stress_test = data_stress[data_stress[\'END_PLAN_DATE\'] < CURRENT_DAY],\\\n                                            data_stress[data_stress[\'END_PLAN_DATE\'] >= CURRENT_DAY]\ntarget_stress_train = target.loc[data_stress_train.index]\n\ndef metric(price, y_true, y_pred):\n    true_val = sum(np.multiply(y_true,price))\n    if true_val == 0:\n        return 1\n    else:\n        return float(sum(np.multiply(y_pred,price)) / true_val)\n\ndef cross_val(X, Y, estimator_type, model):\n    K = 3\n    kf = StratifiedKFold(n_splits=K)\n    test_answers = []\n    pr, metric = 0, 0\n    for train, test in kf.split(X,Y):\n        X_train, X_test = X.iloc[train,:], X.iloc[test,:]\n        y_train, y_test = Y.iloc[train], Y.iloc[test]\n        if estimator_type == \'catboost\':\n            model.fit(X_train,y_train,cat_features=[i for i, c in enumerate(X_train.columns) if c in cat_columns])\n            y_pred = model.predict_proba(X_test)[:,1]\n            test_answers.append([np.array(X_test[\'DEAL_AMOUNT_RUB\']),np.array(y_test),y_pred, model.get_params()])\n    return test_answers\n\ndef find_threshold(price, y_true, y_pred):\n    metric_arr = np.array([metric(price, y_true, (y_pred > (t/400)).astype(int)) for t in range(200)])\n    ind = np.where(metric_arr > 1)\n    if ind[0].shape[0] == 0:\n        return 0\n    return ind[0][int(np.argsort(metric_arr[ind])[0])] / 400\n    \ndef grid_search(estimator_type, param_grid, X, Y):\n    overall_search = []\n    for params in (param_grid):\n        if estimator_type == \'catboost\':\n            model = CatBoostClassifier(**params)\n            test_answers = cross_val(X, Y, estimator_type, model)\n            overall_search.append(test_answers)\n    best_pr = 0\n    best_metric = 1000000\n    best_estimator = None\n    time.sleep(1)\n    for obs in (overall_search):\n        obs_metric, obs_pr, t_mean = 0, 0, []\n        for price, y_test, y_pred, param in obs:\n            t = find_threshold(price, y_test, y_pred)\n            t_mean.append(t)\n            y = (y_pred > t).astype(int)\n            obs_metric += metric(price, y_test, y) / 3\n            obs_pr += average_precision_score(y_test, y) / 3\n        if obs_metric < best_metric:\n            best_pr, best_metric, best_estimator, best_t = obs_pr, obs_metric, param, t_mean\n        else:\n            continue\n    return [best_pr, best_metric, best_estimator, t_mean]\n\n\n# param_grid = ParameterGrid({\'learning_rate\': [0.0005,0.001,0.005,0.01,0.03,0.07,0.1], \'iterations\': [500,300,100], \'depth\': [5,6,7],\\\n#               \'thread_count\':[8], \'random_seed\':[0],\'logging_level\':[\'Silent\']})\n# print(\' BAU\')\n# bau_params = grid_search(\'catboost\', param_grid, data_train.loc[:,\'DEAL_CURRENCY\':], target_train)\n# print(\'\\n\',\'Stress\')\n# stress_params = grid_search(\'catboost\', param_grid, data_stress_train.loc[:,\'DEAL_CURRENCY\':], target_stress_train)\n\nbau_params = dict({\'depth\': 5,\n  \'iterations\': 300,\n  \'learning_rate\': 0.01,\n  \'logging_level\': \'Silent\',\n  \'loss_function\': \'Logloss\',\n  \'random_seed\': 0})\n#bau_threshold 0.0075\n## pr-roc 0.662\n## metric 1.11627\n\nstress_params = dict({\'depth\': 6,\n  \'iterations\': 300,\n  \'learning_rate\': 0.0005,\n  \'logging_level\': \'Silent\',\n  \'loss_function\': \'Logloss\',\n  \'random_seed\': 0})\n#stress_threshold 0.0\n## pr-roc 0.640\n## metric 1.03884\n\ndef predict(model_type, X_train, y_train, X_test, estimator_type):\n    if model_type == \'bau\':\n        threshold = 0.0075\n        params = bau_params.copy()\n    if model_type == \'stress\':\n        threshold = 0.2\n        params = stress_params.copy()\n    \n    if estimator_type == \'catboost\':\n        model = CatBoostClassifier(**params)\n        model.fit(X_train,y_train,cat_features=[i for i, c in enumerate(X_train.columns) if c in cat_columns])\n    y_pred = model.predict_proba(X_test)[:,1]\n    model_result = sum(np.multiply((y_pred > threshold).astype(int),X_test[\'DEAL_AMOUNT_RUB\']))\n    \n    return model_result\n\nbau_result = predict(\'bau\', data_train.loc[:,\'DEAL_CURRENCY\':], target_train, data_test.loc[:,\'DEAL_CURRENCY\':], \'catboost\')\n\nstress_result = predict(\'stress\', data_stress_train.loc[:,\'DEAL_CURRENCY\':], target_stress_train, data_stress_test.loc[:,\'DEAL_CURRENCY\':], \'catboost\')\n\npkl_result = 0.1 * sum(data_stress_test[\'DEAL_AMOUNT_RUB\'])\n\nguarant_result = pd.DataFrame([[CURRENT_DAY,bau_result,stress_result,pkl_result]],columns=[\'VALUE_DAY\',\'BAU\',\'STRESS\',\'PKL\'])\n\ncursor_bi.execute("update GUARANT_OUT")\ncursor_bi.prepare("""insert into NAME (VALUE_DAY, BAU, STRESS, PKL, JOB) \n                  values (:1, :2, :3, :4, 1, date\'"""+dReportDateYYYYMMDD+"\', "+args["job"]+")")\ncursor_bi.executemany(None, guarant_result.values.tolist())\nconn_bi.commit()\n\nconn_bi.close()')

